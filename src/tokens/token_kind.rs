// src/tokens/token_kind.rs
//! Token kind definitions and core token type enumeration.
//!
//! This module provides the `TokenKind` enum which represents all possible
//! lexical token types in the language, generated using the Logos lexer library.

use crate::tokens::number::Number;
use logos::Logos;
use std::fmt;
use std::sync::Arc;

// Re-export parsing modules for use by Logos callbacks
use crate::tokens::parsers::base::{parse_binary, parse_hex, parse_octal};
use crate::tokens::parsers::numeric::parse_number;

/// Represents all possible token types in the language.
///
/// Generated by the lexer and consumed by the parser. Variants include:
/// - Operators
/// - Keywords
/// - Identifiers
/// - Literals
/// - Punctuation
/// - Types
///
/// Uses Logos lexer generation with regex patterns and custom parsers.
#[derive(Logos, Debug, PartialEq, Clone)]
pub enum TokenKind {
    // Operator tokens with correct ordering (longest first)
    #[token("+=")]
    PlusEqual,
    #[token("-=")]
    MinusEqual,
    #[token("==")]
    EqualEqual,
    #[token("!=")]
    NotEqual,
    #[token("<=")]
    LessEqual,
    #[token(">=")]
    GreaterEqual,
    #[token("++")]
    PlusPlus,
    #[token("--")]
    MinusMinus,
    #[token("||")]
    OrOr,
    #[token("&&")]
    AndAnd,
    #[token("<<")]
    ShiftLeft,
    #[token(">>")]
    ShiftRight,
    #[token("%=")]
    PercentEqual,
    #[token("^=")]
    XorEqual,

    // Single-character operators
    #[token("+")]
    Plus,
    #[token("-")]
    Minus,
    #[token("*")]
    Star,
    #[token("/")]
    Slash,
    #[token("<")]
    Less,
    #[token(">")]
    Greater,
    #[token("!")]
    Not,
    #[token("^")]
    Xor,
    #[token("%")]
    Percent,
    #[token("|")]
    Or,
    #[token("&")]
    And,
    #[token("=")]
    Equal,
    #[token(":")]
    Colon,
    #[token(",")]
    Comma,
    #[token(".")]
    Dot,

    // Keywords
    #[token("fun")]
    KeywordFun,
    #[token("if")]
    KeywordIf,
    #[token("else")]
    KeywordElse,
    #[token("return")]
    KeywordReturn,
    #[token("while")]
    KeywordWhile,
    #[token("for")]
    KeywordFor,
    #[token("main")]
    KeywordMain,
    #[token("var")]
    KeywordVar,
    #[token("const")]
    KeywordConst,
    #[token("nullptr")]
    KeywordNullptr,
    #[token("break")]
    KeywordBreak,
    #[token("continue")]
    KeywordContinue,

    // Boolean literals (captures value)
    #[token("false", |_| false)]
    #[token("true", |_| true)]
    KeywordBool(bool),

    // Identifiers
    /// ASCII identifiers (letters, digits, underscores)
    #[regex(r"[a-zA-Z_][a-zA-Z0-9_]*", |lex| Arc::from(lex.slice()), priority = 2)]
    IdentifierAscii(Arc<str>),

    /// Unicode identifiers (supports international characters)
    #[regex(
        r"[\p{Letter}\p{Mark}_][\p{Letter}\p{Mark}\p{Number}_]*",
        |lex| Arc::from(lex.slice()),
        priority = 1
    )]
    IdentifierUnicode(Arc<str>),

    /// Numeric literals (supports integer, float, scientific, and multi-char suffixes)
    #[regex(r"(\d+\.?\d*|\.\d+)([eE][+-]?\d+)?([uUfFdD]|[iIuU](?:8|16|32))?", parse_number, priority = 4)]
    Numeric(Number),

    /// Binary literals (e.g., "#b1010u")
    #[regex(r"#b[01]+[uU]?", parse_binary, priority = 3)]
    Binary(Number),

    /// Octal literals (e.g., "#o755")
    #[regex(r"#o[0-7]+[uU]?", parse_octal, priority = 3)]
    Octal(Number),

    /// Hexadecimal literals (e.g., "#xdeadbeefu")
    #[regex(r"#x[0-9a-fA-F]+[uU]?", parse_hex, priority = 2)]
    Hexadecimal(Number),

    /// String literals (captures content without quotes)
    #[regex(r#""([^"\\]|\\.)*""#, |lex| Arc::from(&lex.slice()[1..lex.slice().len()-1]))]
    StringLiteral(Arc<str>),

    /// Character literals (captures content without quotes)
    #[regex(r#"'([^'\\]|\\.)'"#, |lex| {
        let s = lex.slice();
        Arc::from(&s[1..s.len()-1])
    })]
    CharLiteral(Arc<str>),

    // Parentheses
    #[token("(")]
    OpenParen,
    #[token(")")]
    CloseParen,
    // Square brackets
    #[token("[")]
    OpenBracket,
    #[token("]")]
    CloseBracket,
    // Curly brackets
    #[token("{")]
    OpenBrace,
    #[token("}")]
    CloseBrace,

    // Type keywords
    #[token("i8")]
    TypeI8,
    #[token("i16")]
    TypeI16,
    #[token("i32")]
    TypeI32,
    #[token("i64")]
    TypeI64,
    #[token("u8")]
    TypeU8,
    #[token("u16")]
    TypeU16,
    #[token("u32")]
    TypeU32,
    #[token("u64")]
    TypeU64,
    #[token("f32")]
    TypeF32,
    #[token("f64")]
    TypeF64,
    #[token("char")]
    TypeChar,
    #[token("string")]
    TypeString,
    #[token("bool")]
    TypeBool,

    // Whitespace and comments (skipped by lexer)
    #[regex(r";")]
    Semicolon,
    #[regex(r"\p{White_Space}+", logos::skip)]
    Whitespace,
    /// Matches single-line comments
    #[regex(r"//[^\n\r]*", logos::skip, allow_greedy = true)]
    Comment,
    /// Matches multi-line comments
    #[regex(r"/\*[^*]*\*+(?:[^*/][^*]*\*+)*/", logos::skip)]
    MultilineComment,

    /// End-of-file marker
    Eof,
}

impl TokenKind {
    /// Checks if the token represents a type keyword.
    ///
    /// # Returns
    /// `true` for all type variants (i8, u8, f32, etc.), `false` otherwise
    pub fn is_type(&self) -> bool {
        matches!(
            self,
            TokenKind::TypeI8
                | TokenKind::TypeI16
                | TokenKind::TypeI32
                | TokenKind::TypeI64
                | TokenKind::TypeU8
                | TokenKind::TypeU16
                | TokenKind::TypeU32
                | TokenKind::TypeU64
                | TokenKind::TypeF32
                | TokenKind::TypeF64
                | TokenKind::TypeChar
                | TokenKind::TypeString
                | TokenKind::TypeBool
        )
    }
}

impl fmt::Display for TokenKind {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            // Operators
            TokenKind::Plus => f.write_str("'+'"),
            TokenKind::Minus => f.write_str("'-'"),
            TokenKind::Star => f.write_str("'*'"),
            TokenKind::Slash => f.write_str("'/'"),
            TokenKind::PlusEqual => f.write_str("'+='"),
            TokenKind::MinusEqual => f.write_str("'-='"),
            TokenKind::EqualEqual => f.write_str("'=='"),
            TokenKind::NotEqual => f.write_str("'!='"),
            TokenKind::Less => f.write_str("'<'"),
            TokenKind::Greater => f.write_str("'>'"),
            TokenKind::LessEqual => f.write_str("'<='"),
            TokenKind::GreaterEqual => f.write_str("'>='"),
            TokenKind::PlusPlus => f.write_str("'++'"),
            TokenKind::MinusMinus => f.write_str("'--'"),
            TokenKind::OrOr => f.write_str("'||'"),
            TokenKind::AndAnd => f.write_str("'&&'"),
            TokenKind::ShiftLeft => f.write_str("'<<'"),
            TokenKind::ShiftRight => f.write_str("'>>'"),
            TokenKind::PercentEqual => f.write_str("'%='"),
            TokenKind::XorEqual => f.write_str("'^='"),
            TokenKind::Not => f.write_str("'!'"),
            TokenKind::Xor => f.write_str("'^'"),
            TokenKind::Percent => f.write_str("'%'"),
            TokenKind::Or => f.write_str("'|'"),
            TokenKind::And => f.write_str("'&'"),
            TokenKind::Equal => f.write_str("'='"),
            TokenKind::Colon => f.write_str("':'"),
            TokenKind::Comma => f.write_str("','"),
            TokenKind::Dot => f.write_str("'.'"),
            TokenKind::Semicolon => f.write_str("';'"),

            // Keywords
            TokenKind::KeywordFun => f.write_str("'fun'"),
            TokenKind::KeywordIf => f.write_str("'if'"),
            TokenKind::KeywordElse => f.write_str("'else'"),
            TokenKind::KeywordReturn => f.write_str("'return'"),
            TokenKind::KeywordWhile => f.write_str("'while'"),
            TokenKind::KeywordFor => f.write_str("'for'"),
            TokenKind::KeywordMain => f.write_str("'main'"),
            TokenKind::KeywordVar => f.write_str("'var'"),
            TokenKind::KeywordConst => f.write_str("'const'"),
            TokenKind::KeywordNullptr => f.write_str("'nullptr'"),
            TokenKind::KeywordBreak => f.write_str("'break'"),
            TokenKind::KeywordContinue => f.write_str("'continue'"),
            TokenKind::KeywordBool(b) => write!(f, "boolean '{b}'"),

            // Identifiers
            TokenKind::IdentifierAscii(s) | TokenKind::IdentifierUnicode(s) => {
                write!(f, "identifier '{s}'")
            }

            // Numeric literals
            TokenKind::Numeric(n) => write!(f, "number '{n}'"),
            TokenKind::Binary(n) => write!(f, "binary '{n}'"),
            TokenKind::Octal(n) => write!(f, "octal '{n}'"),
            TokenKind::Hexadecimal(n) => write!(f, "hexadecimal '{n}'"),

            // String/char literals
            TokenKind::StringLiteral(s) => write!(f, "string literal \"{s}\""),
            TokenKind::CharLiteral(c) => write!(f, "character literal '{c}'"),

            // Brackets
            TokenKind::OpenParen => f.write_str("'('"),
            TokenKind::CloseParen => f.write_str("')'"),
            TokenKind::OpenBracket => f.write_str("'['"),
            TokenKind::CloseBracket => f.write_str("']'"),
            TokenKind::OpenBrace => f.write_str("'{'"),
            TokenKind::CloseBrace => f.write_str("'}'"),
            TokenKind::TypeI8 => f.write_str("'i8'"),
            TokenKind::TypeI16 => f.write_str("'i16'"),
            TokenKind::TypeI32 => f.write_str("'i32'"),
            TokenKind::TypeI64 => f.write_str("'i64'"),
            TokenKind::TypeU8 => f.write_str("'u8'"),
            TokenKind::TypeU16 => f.write_str("'u16'"),
            TokenKind::TypeU32 => f.write_str("'u32'"),
            TokenKind::TypeU64 => f.write_str("'u64'"),
            TokenKind::TypeF32 => f.write_str("'f32'"),
            TokenKind::TypeF64 => f.write_str("'f64'"),
            TokenKind::TypeChar => f.write_str("'char'"),
            TokenKind::TypeString => f.write_str("'string'"),
            TokenKind::TypeBool => f.write_str("'bool'"),

            // Special tokens
            TokenKind::Whitespace => f.write_str("whitespace"),
            TokenKind::Comment => f.write_str("comment"),
            TokenKind::MultilineComment => f.write_str("multiline comment"),
            TokenKind::Eof => f.write_str("end of file"),
        }
    }
}
